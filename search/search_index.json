{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The HEAL Platform \u00b6 The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of NIH HEAL results and data. It is designed to serve users with a variety of objectives, backgrounds, and specialties. The HEAL Platform represents a dynamic Data Ecosystem that aggregates and presents data from multiple resources to make data discovery and access easy for users. The platform provides a way to search and query over study metadata and diverse data types, generated by different projects and organizations and stored across multiple secure repositories. The HEAL Platform also offers a secure and cost-effective cloud-computing environment for data analysis, empowering collaborative research and development of new analytical tools. New workflows and results of analyses can be shared with the HEAL community to enable collaborative, high-impact publications that address the opioid crisis. The HEAL Platform is powered by the open-source software \u201cGen3\u201d . Gen3 was created by and is actively developed at the University of Chicago\u2019s Center for Translational Data Science (CTDS) with the aim of creating interoperable cloud-based data resources for the scientific research community. Powered by Watch the introduction video to the HEAL Platform below If your Browser does not support watching this video, here's a link to the video instead.","title":"Home"},{"location":"#the-heal-platform","text":"The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of NIH HEAL results and data. It is designed to serve users with a variety of objectives, backgrounds, and specialties. The HEAL Platform represents a dynamic Data Ecosystem that aggregates and presents data from multiple resources to make data discovery and access easy for users. The platform provides a way to search and query over study metadata and diverse data types, generated by different projects and organizations and stored across multiple secure repositories. The HEAL Platform also offers a secure and cost-effective cloud-computing environment for data analysis, empowering collaborative research and development of new analytical tools. New workflows and results of analyses can be shared with the HEAL community to enable collaborative, high-impact publications that address the opioid crisis. The HEAL Platform is powered by the open-source software \u201cGen3\u201d . Gen3 was created by and is actively developed at the University of Chicago\u2019s Center for Translational Data Science (CTDS) with the aim of creating interoperable cloud-based data resources for the scientific research community. Powered by Watch the introduction video to the HEAL Platform below If your Browser does not support watching this video, here's a link to the video instead.","title":"The HEAL Platform"},{"location":"contact/","text":"Contact \u00b6 Need help? Please contact our help desk . Powered by","title":"Contact"},{"location":"contact/#contact","text":"Need help? Please contact our help desk . Powered by","title":"Contact"},{"location":"data_mgmt_and_repos/","text":"Data Management and Repositories \u00b6 To help HEAL investigators in the repository selection process, the HEAL Data Stewards at RENCI/RTI have developed Repository Selection Criteria and identified a number of recommended repositories. A HEAL-approved repository is a FAIR data repository that is NIH-approved and ideally has an API for metadata and data permissions calls. The following is a non-exhaustive selection of repositories and resources currently made accessible through or leveraged by the Heal Platform: Representation of Data Resources on the HEAL Data Platform. Studies from different Data Resources can be filtered and selected on the Discovery Page in the Study Filters section (top panel): Studies can be filtered by Data Resource using their respective tags. For more information from NIH regarding public access and data sharing, visit https://heal.nih.gov/about/public-access-data .","title":"Data Management and Repositories"},{"location":"data_mgmt_and_repos/#data-management-and-repositories","text":"To help HEAL investigators in the repository selection process, the HEAL Data Stewards at RENCI/RTI have developed Repository Selection Criteria and identified a number of recommended repositories. A HEAL-approved repository is a FAIR data repository that is NIH-approved and ideally has an API for metadata and data permissions calls. The following is a non-exhaustive selection of repositories and resources currently made accessible through or leveraged by the Heal Platform: Representation of Data Resources on the HEAL Data Platform. Studies from different Data Resources can be filtered and selected on the Discovery Page in the Study Filters section (top panel): Studies can be filtered by Data Resource using their respective tags. For more information from NIH regarding public access and data sharing, visit https://heal.nih.gov/about/public-access-data .","title":"Data Management and Repositories"},{"location":"downloading_files/","text":"Data File Downloads \u00b6 Users can download data files associated with a study by downloading the files directly from the Discovery page, or leveraging the CTDS-owned python software development kit (SDK) and the tool \u201cGen3-client\u201d if the file size exceeds 250 MB. Note that current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1. Note, that accessing data files requires linked access to all FAIR enabled repositories, as described here . A pop-up window will remind users: Users are reminded to link the account to all other FAIR enabled repositories, as described here . Download Data Files from the Discovery Page \u00b6 Users can download data files up to sizes of 250 MB directly from the Discovery Page. Below you find the simple steps to do so. Navigate to the Discovery Page . Link your accounts to FAIR repositories as described here . Find the study of interest by using the search features or the list of accessible studies . Select the clickable box next to the study. Click on \"Download ZIP\", which will initiate the data download. Select the study and click \"Download ZIP\". Users will be prompted with a window that shows the download is being prepared. Please do not navigate away from this page until the download is complete. After clicking \"Download ZIP\", your download is being prepared. Please do not navigate away from this page until the download is complete. Users will be notified once the download is ready. If the download doesn't start automatically, please follow the link prompted. Users will be notified once the download is ready. Save the file(s) by selecting the directory using the prompted window. If the file size exceeds 250 MB, users will be notified to deselect studies to reduce the size or use other tools: Users are advised to use other tools to download the files if the total file size exceeds 250 MB. Please see the next section for a step-by-step guide using these tools . Download Data Files using the Gen3-client \u00b6 In order to download data files above 250 MB, users will need to utilize the Gen3-client command line tool developed by the University of Chicago\u2019s Center for Translational Data Science. The current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1. Find below a guide to download data files using the Gen3-client: Log in to the HEAL Platform at https://healdata.org/portal/login . Link your accounts to FAIR repositories as described here . Find and select one or multiple studies of interest on the Discovery Page . For multiple studies, select \"Data Availability\" in the top right corner, click \u201cAvailable\u201d, and choose multiple studies. Click on the button \u201cDownload Manifest\". Select a study of interest, then click on the button \u201cDownload Manifest\". Create and download an API key from your Profile Page . Note where you save the API key on your local machine. Create an API key on the profile page. Download the API key as json file and note the directory where the API key was saved for step 6. Download and configure the Gen3-client a. Follow the download instructions of the Gen3-client here . The client can be downloaded here . b. In your terminal, configure your profile using the following command: gen3-client configure --profile = <profile_name> --cred = <credentials.json> --apiendpoint = <api_endpoint_url> ` Mac/Linux: gen3-client configure --profile = demo --cred = ~/Downloads/demo-credentials.json --apiendpoint = https://healdata.org/ Windows: gen3-client configure --profile=demo --cred=C:\\Users\\demo\\Downloads\\demo-credentials.json --apiendpoint=https://healdata.org/ If the command was succesful, you should get the following output: 10:08:20 Profile 'demo' has been configured successfully. If successfully executed, a configuration file will be stored under the directory the user specified under \u201ccred\u201d. For troubleshooting, refer to the instructions found here . c. Download files by using the following command, which references the manifest file name and its location: gen3-client download-multiple --profile = <profile_name> --manifest = <manifest_file> --download-path = <path_for_files> For example: gen3-client download-multiple --profile = demo --manifest = manifest.json --download-path = downloads 2021 /06/03 16 :48:46 Reading manifest... 200 B / 200 B [===================] 100 .00% 0s WARNING: flag \"rename\" was set to false in \"original\" mode, duplicated files under \"downloads/\" will be overwritten Proceed? [ y/n ] : Enter: y Output: 2021 /06/03 16 :48:47 Total number of GUIDs: 1 2021 /06/03 16 :48:47 Preparing file info for each file, please wait... 1 / 1 [============================================] 100 .00% 0s 2021 /06/03 16 :48:47 File info prepared successfully arcos_all_washpost.tsv.gz 6 .41 GiB / 6 .41 GiB [=======================================================] 100 .00% 0s Download Data Files in Workspaces using the Python SDK \u00b6 Users can download data files to the workspaces by leveraging the CTDS-owned python software development kit (SDK). Follow instructions below. Log in to the Data Commons at https://healdata.org/portal/login . Link your accounts to FAIR repositories as described here . Find and select one or multiple studies of interest on the Discovery Page . Select \"Data Availability\" in the top right corner and click on \u201cAvailable\u201d to see all available studies. Select a study and click on \"Open in Workspace\". Select a workspace VM and click \"Launch\". Choose the \"(Generic) Jupyter Notebook with R kernel\" if you are familiar with setting up Python- or R-based Notebooks, or if you just exported one or multiple studies from the Discovery Page and want to start your custom analysis. Choose a VM with the name of the Notebook if you selected the studies relevant to a specific Notebook and want to work on the Notebook in interactive mode. Available workspaces on the HEAL Platform (top). Users need to link accounts from other repositories (bottom; click here to see how ). Find all files under /data/healdata.org/ with the ending \"PLACEHOLDER\". These files can be directly downloaded either in the terminal or in a notebook cell. Click on one file and copy the command and GUID. Open a new terminal under \"New\". Type in the following command to download the file to the terminal: gen3 drs-pull object \"guid\" If you are working in a notebook, type in the following command into a code cell to download the file: !gen3 drs-pull object \"guid\" If you use the R kernel, change the command into system(\"gen3 drs-pull object 'guid'\") Note, that you can also use the manifest.json to download in batches, see below: Download files in batches with a file manifest using the commands shown above. The file(s) should be downloaded and is ready to be worked with in your Notebook. Downloaded files can be found in your home directory.","title":"Data File Downloads"},{"location":"downloading_files/#data-file-downloads","text":"Users can download data files associated with a study by downloading the files directly from the Discovery page, or leveraging the CTDS-owned python software development kit (SDK) and the tool \u201cGen3-client\u201d if the file size exceeds 250 MB. Note that current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1. Note, that accessing data files requires linked access to all FAIR enabled repositories, as described here . A pop-up window will remind users: Users are reminded to link the account to all other FAIR enabled repositories, as described here .","title":"Data File Downloads"},{"location":"downloading_files/#download-data-files-from-the-discovery-page","text":"Users can download data files up to sizes of 250 MB directly from the Discovery Page. Below you find the simple steps to do so. Navigate to the Discovery Page . Link your accounts to FAIR repositories as described here . Find the study of interest by using the search features or the list of accessible studies . Select the clickable box next to the study. Click on \"Download ZIP\", which will initiate the data download. Select the study and click \"Download ZIP\". Users will be prompted with a window that shows the download is being prepared. Please do not navigate away from this page until the download is complete. After clicking \"Download ZIP\", your download is being prepared. Please do not navigate away from this page until the download is complete. Users will be notified once the download is ready. If the download doesn't start automatically, please follow the link prompted. Users will be notified once the download is ready. Save the file(s) by selecting the directory using the prompted window. If the file size exceeds 250 MB, users will be notified to deselect studies to reduce the size or use other tools: Users are advised to use other tools to download the files if the total file size exceeds 250 MB. Please see the next section for a step-by-step guide using these tools .","title":"Download Data Files from the Discovery Page"},{"location":"downloading_files/#download-data-files-using-the-gen3-client","text":"In order to download data files above 250 MB, users will need to utilize the Gen3-client command line tool developed by the University of Chicago\u2019s Center for Translational Data Science. The current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1. Find below a guide to download data files using the Gen3-client: Log in to the HEAL Platform at https://healdata.org/portal/login . Link your accounts to FAIR repositories as described here . Find and select one or multiple studies of interest on the Discovery Page . For multiple studies, select \"Data Availability\" in the top right corner, click \u201cAvailable\u201d, and choose multiple studies. Click on the button \u201cDownload Manifest\". Select a study of interest, then click on the button \u201cDownload Manifest\". Create and download an API key from your Profile Page . Note where you save the API key on your local machine. Create an API key on the profile page. Download the API key as json file and note the directory where the API key was saved for step 6. Download and configure the Gen3-client a. Follow the download instructions of the Gen3-client here . The client can be downloaded here . b. In your terminal, configure your profile using the following command: gen3-client configure --profile = <profile_name> --cred = <credentials.json> --apiendpoint = <api_endpoint_url> ` Mac/Linux: gen3-client configure --profile = demo --cred = ~/Downloads/demo-credentials.json --apiendpoint = https://healdata.org/ Windows: gen3-client configure --profile=demo --cred=C:\\Users\\demo\\Downloads\\demo-credentials.json --apiendpoint=https://healdata.org/ If the command was succesful, you should get the following output: 10:08:20 Profile 'demo' has been configured successfully. If successfully executed, a configuration file will be stored under the directory the user specified under \u201ccred\u201d. For troubleshooting, refer to the instructions found here . c. Download files by using the following command, which references the manifest file name and its location: gen3-client download-multiple --profile = <profile_name> --manifest = <manifest_file> --download-path = <path_for_files> For example: gen3-client download-multiple --profile = demo --manifest = manifest.json --download-path = downloads 2021 /06/03 16 :48:46 Reading manifest... 200 B / 200 B [===================] 100 .00% 0s WARNING: flag \"rename\" was set to false in \"original\" mode, duplicated files under \"downloads/\" will be overwritten Proceed? [ y/n ] : Enter: y Output: 2021 /06/03 16 :48:47 Total number of GUIDs: 1 2021 /06/03 16 :48:47 Preparing file info for each file, please wait... 1 / 1 [============================================] 100 .00% 0s 2021 /06/03 16 :48:47 File info prepared successfully arcos_all_washpost.tsv.gz 6 .41 GiB / 6 .41 GiB [=======================================================] 100 .00% 0s","title":"Download Data Files using the Gen3-client"},{"location":"downloading_files/#download-data-files-in-workspaces-using-the-python-sdk","text":"Users can download data files to the workspaces by leveraging the CTDS-owned python software development kit (SDK). Follow instructions below. Log in to the Data Commons at https://healdata.org/portal/login . Link your accounts to FAIR repositories as described here . Find and select one or multiple studies of interest on the Discovery Page . Select \"Data Availability\" in the top right corner and click on \u201cAvailable\u201d to see all available studies. Select a study and click on \"Open in Workspace\". Select a workspace VM and click \"Launch\". Choose the \"(Generic) Jupyter Notebook with R kernel\" if you are familiar with setting up Python- or R-based Notebooks, or if you just exported one or multiple studies from the Discovery Page and want to start your custom analysis. Choose a VM with the name of the Notebook if you selected the studies relevant to a specific Notebook and want to work on the Notebook in interactive mode. Available workspaces on the HEAL Platform (top). Users need to link accounts from other repositories (bottom; click here to see how ). Find all files under /data/healdata.org/ with the ending \"PLACEHOLDER\". These files can be directly downloaded either in the terminal or in a notebook cell. Click on one file and copy the command and GUID. Open a new terminal under \"New\". Type in the following command to download the file to the terminal: gen3 drs-pull object \"guid\" If you are working in a notebook, type in the following command into a code cell to download the file: !gen3 drs-pull object \"guid\" If you use the R kernel, change the command into system(\"gen3 drs-pull object 'guid'\") Note, that you can also use the manifest.json to download in batches, see below: Download files in batches with a file manifest using the commands shown above. The file(s) should be downloaded and is ready to be worked with in your Notebook. Downloaded files can be found in your home directory.","title":"Download Data Files in Workspaces using the Python SDK"},{"location":"faqs/","text":"FAQs \u00b6 What can I do on the HEAL Platform? The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of HEAL results and data. Explore all functionalities here . Which datasets are currently open-access? Find all open-access datasets here . Where can I see individual study metadata? Individual study metadata is shown upon clicking on a study entry on the Discovery Page. Click to read the full description here . Do I need to store my data in a particular location to participate in the HEAL platform? You must store your data in a HEAL-approved repository. A HEAL-approved repository is a data repository that is NIH-approved and ideally has an API for metadata and data permissions calls. To help HEAL investigators in the repository selection process, the HEAL Data Stewards at RENCI/RTI have developed Repository Selection Criteria and identified a number of recommended repositories. If you have questions regarding costs associated with data storage in HEAL-approved repositories, please contact the HEAL Data Stewards . How and where can I see if I have access to a study? Clicking on an individual study on the Discovery Page will show in the top right corner if they are accessible to the user. To see all studies users have access to, users should navigate to the Discovery Page and select \u201cData Availability\u201d - Available\u201d. More information here . I do not have access to a specific study, how can I get access? RENCI/RTI (Renaissance Computing Institute) at the University of North Carolina at Chapel Hill establishes and manages data access contacts over all data contributors/sources. To request access to controlled data, users should contact RENCI/RTI at HEALstewards@renci.org. The profile page says I have access but I don\u2019t see it on the Discovery Page. Please contact our help desk . I would like to download data files from a specific study, what do I need to do? Users can download the studies directly from the Discovery Page as described here , or, if the file size exceeds 250 MB, users need to use the Gen3-client command line tool to download data files, as described here . Additional information on the Gen3-client may be found here . How can I get data files into the Workspace from the Discovery Page? Click here to follow the steps on how to get files from the Discovery Page to the Workspace. How do I find a study? Click here to see possible ways to search for a study on the Discovery Page. Can I download files directly from the portal? Yes, you can. Click here to follow the steps to download data files from the Discovery Page. Caution: the download is limited to file sizes of 250 MB. My download is not working. Please check if your file size exceeds 250 MB. If yes, please other tools as described here to download the files. Note that the current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1. If errors persist, please contact the help desk . My data file download using the Gen3-client gets stuck, where can I get help? For troubleshooting, please see the Gen3-client documentation here . If errors persist, contact our help desk . The Gen3-client shows errors, where can I get help? To check that the client is working and to confirm the client version, type \u2018gen3-client\u2019 in the terminal. Typing \u2018gen3-client help\u2019 will display the help menu. Users must provide the full path of the tool in order for the commands to run, for example, \u2018./gen3-client\u2019 while working from the directory containing the client. For more troubleshooting, please see the Gen3-client documentation here . If errors persist, contact our help desk . I want to work interactively on the Tutorial Notebooks. Show me how. Click here to follow the steps of a demo. What are the current Tutorial Notebooks? Click here to see a list of currently available Notebooks in Python and R. How do I work with these Tutorial Notebooks? Click here to see a guide of how to work with the Tutorial Notebooks. How do I link my account to a FAIR enabled repository? Click here to see how to link your account to a FAIR enabled repository. What do the Workspaces have to offer? Click here to see how to get started and here to see what languages, tools, and environments the workspaces have enabled. I want to report a bug! Please report any errors or bugs to our help desk .","title":"FAQs"},{"location":"faqs/#faqs","text":"What can I do on the HEAL Platform? The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of HEAL results and data. Explore all functionalities here . Which datasets are currently open-access? Find all open-access datasets here . Where can I see individual study metadata? Individual study metadata is shown upon clicking on a study entry on the Discovery Page. Click to read the full description here . Do I need to store my data in a particular location to participate in the HEAL platform? You must store your data in a HEAL-approved repository. A HEAL-approved repository is a data repository that is NIH-approved and ideally has an API for metadata and data permissions calls. To help HEAL investigators in the repository selection process, the HEAL Data Stewards at RENCI/RTI have developed Repository Selection Criteria and identified a number of recommended repositories. If you have questions regarding costs associated with data storage in HEAL-approved repositories, please contact the HEAL Data Stewards . How and where can I see if I have access to a study? Clicking on an individual study on the Discovery Page will show in the top right corner if they are accessible to the user. To see all studies users have access to, users should navigate to the Discovery Page and select \u201cData Availability\u201d - Available\u201d. More information here . I do not have access to a specific study, how can I get access? RENCI/RTI (Renaissance Computing Institute) at the University of North Carolina at Chapel Hill establishes and manages data access contacts over all data contributors/sources. To request access to controlled data, users should contact RENCI/RTI at HEALstewards@renci.org. The profile page says I have access but I don\u2019t see it on the Discovery Page. Please contact our help desk . I would like to download data files from a specific study, what do I need to do? Users can download the studies directly from the Discovery Page as described here , or, if the file size exceeds 250 MB, users need to use the Gen3-client command line tool to download data files, as described here . Additional information on the Gen3-client may be found here . How can I get data files into the Workspace from the Discovery Page? Click here to follow the steps on how to get files from the Discovery Page to the Workspace. How do I find a study? Click here to see possible ways to search for a study on the Discovery Page. Can I download files directly from the portal? Yes, you can. Click here to follow the steps to download data files from the Discovery Page. Caution: the download is limited to file sizes of 250 MB. My download is not working. Please check if your file size exceeds 250 MB. If yes, please other tools as described here to download the files. Note that the current studies that have datasets of more than 250 MB are those with the following project numbers: a) cdcwonder and b) deaarcos1. If errors persist, please contact the help desk . My data file download using the Gen3-client gets stuck, where can I get help? For troubleshooting, please see the Gen3-client documentation here . If errors persist, contact our help desk . The Gen3-client shows errors, where can I get help? To check that the client is working and to confirm the client version, type \u2018gen3-client\u2019 in the terminal. Typing \u2018gen3-client help\u2019 will display the help menu. Users must provide the full path of the tool in order for the commands to run, for example, \u2018./gen3-client\u2019 while working from the directory containing the client. For more troubleshooting, please see the Gen3-client documentation here . If errors persist, contact our help desk . I want to work interactively on the Tutorial Notebooks. Show me how. Click here to follow the steps of a demo. What are the current Tutorial Notebooks? Click here to see a list of currently available Notebooks in Python and R. How do I work with these Tutorial Notebooks? Click here to see a guide of how to work with the Tutorial Notebooks. How do I link my account to a FAIR enabled repository? Click here to see how to link your account to a FAIR enabled repository. What do the Workspaces have to offer? Click here to see how to get started and here to see what languages, tools, and environments the workspaces have enabled. I want to report a bug! Please report any errors or bugs to our help desk .","title":"FAQs"},{"location":"heal_workspace_registration/","text":"Register for HEAL Data Platform Workspaces \u00b6 To start exploring HEAL Data Platform Workspaces, users can apply for Temporary Trial Access. Extended access to HEAL Data Platform Workspaces is granted using an NIH STRIDES workspace account, which can be requested after trial access is provisioned. Please see below for more details. Guidelines for Requesting Temporary Trial Access to HEAL Data Platform Workspaces \u00b6 For new users without workspace access, please follow these steps Login to the HEAL Data Platform Click on the Workspace tab . This opens the Workspace Access Request form Fill in the details and submit the form shown below. The form should be completed only once. Following submission, users will see a success message and a link back to the Discovery page. Users will receive an email notifying them that the request has been received. Users will receive another email notifying them the temporary trial access request has been approved. They should then be able to access workspaces on the HEAL Data Platform.. Please note that the timeline for this approval can be a few business days. Guidelines for Requesting Extended Access to HEAL Data Platform Workspaces using STRIDES \u00b6 Please Note: The process for granting access for a workspace account through NIH STRIDES can take up to two weeks. The workspace account is handled with the help of NIH STRIDES (NIH S cience and T echnology R esearch I nfrastructure for D iscovery, E xperimentation, and S ustainability). The NIH STRIDES Initiative allows NIH to explore the use of cloud environments to streamline NIH data use by partnering with commercial providers. By leveraging the STRIDES Initiative, NIH and NIH-funded institutions can begin to create a robust, interconnected ecosystem that breaks down silos related to generating, analyzing, and sharing research data. NIH-funded researchers with an active NIH award may take advantage of the STRIDES Initiative for their NIH-funded research projects. Eligible researchers include NIH intramural researchers and awardees of NIH contracts, other transaction agreements, grants, cooperative agreements, and other agreements. More information on NIH STRIDES and how to gain access can be found here . Please see below for registration steps Users will receive an invitation via email to register for an NIH STRIDES workspace account. Users can click the link in the invitation email or request a workspace account by visiting https://healportal.org/ and logging in. After authorization, users will be able to see active workspace accounts and credits. To request a workspace account, select \"Request New Workspace\" on the landing page. Choose one of the two options a) STRIDES Grant/Award Funded or b) STRIDES Credits to request a workspace account. For information on the NIH STRIDES options, please refer to the official page . The STRIDES Grant/Award Funded form can be selected if researchers have received NIH funding (e.g. a grant, contract, cooperative agreement, or other transaction agreement) and intend to use these funds for a HEAL Data Platform Workspace account. With this option, the researchers' organization will be responsible for payment. Select the STRIDES Credits form to request credits from the NIH STRIDES Initiative for the HEAL Data Platform Workspace account. With this option, once the request is approved, a new account with a spending limit of $XXX will be provisioned for usage. Submit the request. Note that the process of granting access for a workspace account can take up to two weeks and users will be notified. Following the approval, users will see the current workspace accounts and credits on the landing page.","title":"Workspace Registration"},{"location":"heal_workspace_registration/#register-for-heal-data-platform-workspaces","text":"To start exploring HEAL Data Platform Workspaces, users can apply for Temporary Trial Access. Extended access to HEAL Data Platform Workspaces is granted using an NIH STRIDES workspace account, which can be requested after trial access is provisioned. Please see below for more details.","title":"Register for HEAL Data Platform Workspaces"},{"location":"heal_workspace_registration/#guidelines-for-requesting-temporary-trial-access-to-heal-data-platform-workspaces","text":"For new users without workspace access, please follow these steps Login to the HEAL Data Platform Click on the Workspace tab . This opens the Workspace Access Request form Fill in the details and submit the form shown below. The form should be completed only once. Following submission, users will see a success message and a link back to the Discovery page. Users will receive an email notifying them that the request has been received. Users will receive another email notifying them the temporary trial access request has been approved. They should then be able to access workspaces on the HEAL Data Platform.. Please note that the timeline for this approval can be a few business days.","title":"Guidelines for Requesting Temporary Trial Access to HEAL Data Platform Workspaces"},{"location":"heal_workspace_registration/#guidelines-for-requesting-extended-access-to-heal-data-platform-workspaces-using-strides","text":"Please Note: The process for granting access for a workspace account through NIH STRIDES can take up to two weeks. The workspace account is handled with the help of NIH STRIDES (NIH S cience and T echnology R esearch I nfrastructure for D iscovery, E xperimentation, and S ustainability). The NIH STRIDES Initiative allows NIH to explore the use of cloud environments to streamline NIH data use by partnering with commercial providers. By leveraging the STRIDES Initiative, NIH and NIH-funded institutions can begin to create a robust, interconnected ecosystem that breaks down silos related to generating, analyzing, and sharing research data. NIH-funded researchers with an active NIH award may take advantage of the STRIDES Initiative for their NIH-funded research projects. Eligible researchers include NIH intramural researchers and awardees of NIH contracts, other transaction agreements, grants, cooperative agreements, and other agreements. More information on NIH STRIDES and how to gain access can be found here . Please see below for registration steps Users will receive an invitation via email to register for an NIH STRIDES workspace account. Users can click the link in the invitation email or request a workspace account by visiting https://healportal.org/ and logging in. After authorization, users will be able to see active workspace accounts and credits. To request a workspace account, select \"Request New Workspace\" on the landing page. Choose one of the two options a) STRIDES Grant/Award Funded or b) STRIDES Credits to request a workspace account. For information on the NIH STRIDES options, please refer to the official page . The STRIDES Grant/Award Funded form can be selected if researchers have received NIH funding (e.g. a grant, contract, cooperative agreement, or other transaction agreement) and intend to use these funds for a HEAL Data Platform Workspace account. With this option, the researchers' organization will be responsible for payment. Select the STRIDES Credits form to request credits from the NIH STRIDES Initiative for the HEAL Data Platform Workspace account. With this option, once the request is approved, a new account with a spending limit of $XXX will be provisioned for usage. Submit the request. Note that the process of granting access for a workspace account can take up to two weeks and users will be notified. Following the approval, users will see the current workspace accounts and credits on the landing page.","title":"Guidelines for Requesting Extended Access to HEAL Data Platform Workspaces using STRIDES"},{"location":"hosted_data_types/","text":"Types of Hosted Data \u00b6 As part of the NIH HEAL Initiative, the HEAL Platform aims to transform opioid research into a virtual, annotated, searchable catalog where data from different studies can be analyzed, compared, and combined. The data presented on the HEAL Platform are diverse and include scientific research across multiple disciplines. For example, researchers can use this single platform to find clinical patient care data and public records as well as \u201c-omics\u201d data files with associated sample collection and processing data. The HEAL platform aims to make data more accessible by following the \" FAIR \" principles: F indable Researchers are provided an intuitive interface to search over metadata for HEAL studies and related datasets. Each study and dataset will be assigned a unique, persistent identifier. A ccessible Authenticated users can request and receive access to controlled-access data by data providers. Metadata can be accessed via an open API. I nteroperable Standard metadata vocabularies facilitate discovery and joint analysis of HEAL and related datasets. Data can Data can be easily exported to various workspaces for analysis using a variety of software tools. R eusable Data can be easily reused to facilitate reproducibility of results, development and sharing of new tools, and collaboration between investigators. FAIR data repositories are traditionally a part of a larger institution established for research, data archiving, and, to serve data users of that organization.","title":"Types of Hosted Data"},{"location":"hosted_data_types/#types-of-hosted-data","text":"As part of the NIH HEAL Initiative, the HEAL Platform aims to transform opioid research into a virtual, annotated, searchable catalog where data from different studies can be analyzed, compared, and combined. The data presented on the HEAL Platform are diverse and include scientific research across multiple disciplines. For example, researchers can use this single platform to find clinical patient care data and public records as well as \u201c-omics\u201d data files with associated sample collection and processing data. The HEAL platform aims to make data more accessible by following the \" FAIR \" principles: F indable Researchers are provided an intuitive interface to search over metadata for HEAL studies and related datasets. Each study and dataset will be assigned a unique, persistent identifier. A ccessible Authenticated users can request and receive access to controlled-access data by data providers. Metadata can be accessed via an open API. I nteroperable Standard metadata vocabularies facilitate discovery and joint analysis of HEAL and related datasets. Data can Data can be easily exported to various workspaces for analysis using a variety of software tools. R eusable Data can be easily reused to facilitate reproducibility of results, development and sharing of new tools, and collaboration between investigators. FAIR data repositories are traditionally a part of a larger institution established for research, data archiving, and, to serve data users of that organization.","title":"Types of Hosted Data"},{"location":"logging-in/","text":"Logging In to the Platform \u00b6 You will not need to log in in order to: browse the study metadata on the Discovery Page read the pre-made tutorial notebooks in the \u201cExample Analysis\u201d tab You will need to log in and obtain authorization (access) in order to: register your own study access studies with controlled data perform analyses in workspaces download data files and file manifests run interactive tutorial notebooks in workspaces Start by visiting the login page . Login Page Options \u00b6 Login from Google : You may login using any Google account credentials, or a G-suite enabled institutional email. This option may or may not be available depending on the institution or organization the user is associated with. Users should contact the IT support to verify if this option is available. For staff, students, and faculty of the University of Chicago, more information can be found here . ORCID Login : Users with an ORCID account can log in using their ORCID credentials. InCommon Login : Users can login with a participating institution that is federated by InCommon. Click on \u201cSelect...\u201d to browse and choose the institution. After successfully logging in, your username will appear in the upper right-hand corner of the page.","title":"Logging In"},{"location":"logging-in/#logging-in-to-the-platform","text":"You will not need to log in in order to: browse the study metadata on the Discovery Page read the pre-made tutorial notebooks in the \u201cExample Analysis\u201d tab You will need to log in and obtain authorization (access) in order to: register your own study access studies with controlled data perform analyses in workspaces download data files and file manifests run interactive tutorial notebooks in workspaces Start by visiting the login page .","title":"Logging In to the Platform"},{"location":"logging-in/#login-page-options","text":"Login from Google : You may login using any Google account credentials, or a G-suite enabled institutional email. This option may or may not be available depending on the institution or organization the user is associated with. Users should contact the IT support to verify if this option is available. For staff, students, and faculty of the University of Chicago, more information can be found here . ORCID Login : Users with an ORCID account can log in using their ORCID credentials. InCommon Login : Users can login with a participating institution that is federated by InCommon. Click on \u201cSelect...\u201d to browse and choose the institution. After successfully logging in, your username will appear in the upper right-hand corner of the page.","title":"Login Page Options"},{"location":"platform_discovery_page/","text":"Discovery Page \u00b6 The Discovery Page provides users a venue to search and find studies and datasets displayed in the HEAL Platform. Users can browse through the publicly accessible study-level metadata without requiring authorization. Use text-based search, faceted search, and tags to rapidly and efficiently find relevant studies, discover new datasets across multiple resources, and easily export selected data files to the analysis workspace. The Discovery Page of the HEAL Platform. Browse through datasets and study-level metadata and find studies using tags or the free text search field. Search Features \u00b6 Different features such as free text search bar and tags on the Discovery Page help navigating and refining the search. Free Text Search. Finding studies is made easy using keywords in the free text-based search bar or using tags. The free-text search bar can be used to search for study title, investigator name, or any keyword that is mentioned in the metadata of the study. Type in any keyword mentioned in the metadata, except for what is stored as Tags in \"Study Characteristics\". Study Characteristics. Click \"Study Characteristics\" to expand the search options. Find a range of tags in eight categories (Study Setting, Study Design, Pain, Data Type, Subject Characteristics, Intervention/Treatment, Substance Use, Data Resources) to narrow down any search. Selecting multiple tags work in a \"OR\" logic. Click on \"Reset Selection\" to start a new search. The total number of studies. Shows the amount of studies the HEAL Platform is currently displaying. Export Options. Login first to leverage the export options. Select one or multiple studies and 1) download the attached data files, 2) download a file manifest (for data files whose sizes exceed 250 MB), or 3) export the metadata and data files to a secure cloud environment \"Workspaces\" to start your custom data analysis in Python, R, or Stata. Studies. This feature presents all current studies on the HEAL Platform. Click on any study to show useful information about the study (metadata). Data Availability. Filter on available, pending, and not-yet-available datasets. Documentation. This brings you to this page you are currently on. Login Page. Login on the HEAL Platform to leverage all features. Read further here . Find available Study-level Metadata \u00b6 Finding available study-level metadata on the HEAL Platform is made easy by clicking on a study. Clicking on any study will display the available study-level and dataset metadata. Find accessible Datasets \u00b6 Users can select and filter studies from multiple resources and conduct analyses on the selected datasets in a workspace. Users can find search only available data they have access to by selecting the data access button in the top right corner of the study page and selecting \u201cData Availability\" - \"Available\" as shown below. The Discovery Page will automatically update the list of studies that have available datasets. Select the symbol next to Data Availability to open all options. Three options are available. Find available datasets by clicking on the \u201cAvailable\u201d button. Data Availability Options \u00b6 Different options for Data Availability exist and will be explained below. Three options for Data Availability. Available: This option will display only studies with datasets users have access to and entails all open-access studies. Studies can be selected and exported to a workspace or downloaded by clicking on the associated checkbox on the left-hand side of the study entry and selecting one of the options in the top right. Once available, each study can be selected and exported to workspace or downloaded. Not available: This option will filter out all studies that will only have metadata but no datasets available. The checkbox next to the study will be greyed out and non-clickable. Studies will grey out if they're not available, have no data attached, users have no access to, or are in pending mode. Pending: This option will display studies located on any data resource or repository, for which attached datasets will be added in the near future. The checkbox next to the study will be greyed out and non-clickable as shown above. Select Files on the Discovery Page and bring them to the Workspace \u00b6 The above gif shows the workflow used to select data files from the Discovery Page and bring them into the workspace using Jupyter Notebooks. Log in at https://healdata.org/portal/login . Link your account to all FAIR repositories as described here . Find and select the study by the project number (in this example: 1U2CDA050098-01_a) on the Discovery Page . Find other current open-access studies here . Click the \u201cOpen in Workspace\u201d button in the upper right corner. This step will create a manifest folder which you can find later in the Workspace\u2019s folder \"data/healdata.org\". Select the study and click on \u201cOpen in Workspace\u201d. Choose a workspace flavor and click \"Launch\". This step may take several minutes. Navigate to the /pd/data/healdata.org/ folder and find the placeholder files there. Click on those placeholder files to find instructions how to download the files or see below. From the directory /pd , users can now start a new notebook. Click \u201cNew\u201d (upper right corner) or open a previously saved notebook on the landing drive to load the files into one of the cells, for example by running: ! gen3 drs-pull object \"guid\" import pandas as pd os.chdir('/pd') demo_df = pd.read_csv('pd/demo_file.txt', sep='\\t') demo_df.head() More information for instructions on importing data can be found in the sections \"Download Files to Workspaces\" and \"Workspaces\" . Make sure to terminate the workspace when the work is finished to reduce computational costs. \"pd\" means persistent directory. Saved files outside this directory will be lost. The manifest.json lists metadata of all exported files and can be used to download in batches Note, that all exported data files will be saved in the /pd/data/healdata.org/ folder. Please also note, that the workspace mounts up to a maximum of 5 different manifests while the workspace is running but shows only the latest exported manifest in a newly launched workspace. Terminating the workspace will result in the loss of all but the latests manifest.","title":"Discovery Page"},{"location":"platform_discovery_page/#discovery-page","text":"The Discovery Page provides users a venue to search and find studies and datasets displayed in the HEAL Platform. Users can browse through the publicly accessible study-level metadata without requiring authorization. Use text-based search, faceted search, and tags to rapidly and efficiently find relevant studies, discover new datasets across multiple resources, and easily export selected data files to the analysis workspace. The Discovery Page of the HEAL Platform. Browse through datasets and study-level metadata and find studies using tags or the free text search field.","title":"Discovery Page"},{"location":"platform_discovery_page/#search-features","text":"Different features such as free text search bar and tags on the Discovery Page help navigating and refining the search. Free Text Search. Finding studies is made easy using keywords in the free text-based search bar or using tags. The free-text search bar can be used to search for study title, investigator name, or any keyword that is mentioned in the metadata of the study. Type in any keyword mentioned in the metadata, except for what is stored as Tags in \"Study Characteristics\". Study Characteristics. Click \"Study Characteristics\" to expand the search options. Find a range of tags in eight categories (Study Setting, Study Design, Pain, Data Type, Subject Characteristics, Intervention/Treatment, Substance Use, Data Resources) to narrow down any search. Selecting multiple tags work in a \"OR\" logic. Click on \"Reset Selection\" to start a new search. The total number of studies. Shows the amount of studies the HEAL Platform is currently displaying. Export Options. Login first to leverage the export options. Select one or multiple studies and 1) download the attached data files, 2) download a file manifest (for data files whose sizes exceed 250 MB), or 3) export the metadata and data files to a secure cloud environment \"Workspaces\" to start your custom data analysis in Python, R, or Stata. Studies. This feature presents all current studies on the HEAL Platform. Click on any study to show useful information about the study (metadata). Data Availability. Filter on available, pending, and not-yet-available datasets. Documentation. This brings you to this page you are currently on. Login Page. Login on the HEAL Platform to leverage all features. Read further here .","title":"Search Features"},{"location":"platform_discovery_page/#find-available-study-level-metadata","text":"Finding available study-level metadata on the HEAL Platform is made easy by clicking on a study. Clicking on any study will display the available study-level and dataset metadata.","title":"Find available Study-level Metadata"},{"location":"platform_discovery_page/#find-accessible-datasets","text":"Users can select and filter studies from multiple resources and conduct analyses on the selected datasets in a workspace. Users can find search only available data they have access to by selecting the data access button in the top right corner of the study page and selecting \u201cData Availability\" - \"Available\" as shown below. The Discovery Page will automatically update the list of studies that have available datasets. Select the symbol next to Data Availability to open all options. Three options are available. Find available datasets by clicking on the \u201cAvailable\u201d button.","title":"Find accessible Datasets"},{"location":"platform_discovery_page/#data-availability-options","text":"Different options for Data Availability exist and will be explained below. Three options for Data Availability. Available: This option will display only studies with datasets users have access to and entails all open-access studies. Studies can be selected and exported to a workspace or downloaded by clicking on the associated checkbox on the left-hand side of the study entry and selecting one of the options in the top right. Once available, each study can be selected and exported to workspace or downloaded. Not available: This option will filter out all studies that will only have metadata but no datasets available. The checkbox next to the study will be greyed out and non-clickable. Studies will grey out if they're not available, have no data attached, users have no access to, or are in pending mode. Pending: This option will display studies located on any data resource or repository, for which attached datasets will be added in the near future. The checkbox next to the study will be greyed out and non-clickable as shown above.","title":"Data Availability Options"},{"location":"platform_discovery_page/#select-files-on-the-discovery-page-and-bring-them-to-the-workspace","text":"The above gif shows the workflow used to select data files from the Discovery Page and bring them into the workspace using Jupyter Notebooks. Log in at https://healdata.org/portal/login . Link your account to all FAIR repositories as described here . Find and select the study by the project number (in this example: 1U2CDA050098-01_a) on the Discovery Page . Find other current open-access studies here . Click the \u201cOpen in Workspace\u201d button in the upper right corner. This step will create a manifest folder which you can find later in the Workspace\u2019s folder \"data/healdata.org\". Select the study and click on \u201cOpen in Workspace\u201d. Choose a workspace flavor and click \"Launch\". This step may take several minutes. Navigate to the /pd/data/healdata.org/ folder and find the placeholder files there. Click on those placeholder files to find instructions how to download the files or see below. From the directory /pd , users can now start a new notebook. Click \u201cNew\u201d (upper right corner) or open a previously saved notebook on the landing drive to load the files into one of the cells, for example by running: ! gen3 drs-pull object \"guid\" import pandas as pd os.chdir('/pd') demo_df = pd.read_csv('pd/demo_file.txt', sep='\\t') demo_df.head() More information for instructions on importing data can be found in the sections \"Download Files to Workspaces\" and \"Workspaces\" . Make sure to terminate the workspace when the work is finished to reduce computational costs. \"pd\" means persistent directory. Saved files outside this directory will be lost. The manifest.json lists metadata of all exported files and can be used to download in batches Note, that all exported data files will be saved in the /pd/data/healdata.org/ folder. Please also note, that the workspace mounts up to a maximum of 5 different manifests while the workspace is running but shows only the latest exported manifest in a newly launched workspace. Terminating the workspace will result in the loss of all but the latests manifest.","title":"Select Files on the Discovery Page and bring them to the Workspace"},{"location":"platform_example_analyses/","text":"Example Analyses \u00b6 The Example Analysis page contains a collection of view-only tutorial Jupyter Notebooks that provide demo analyses of datasets published on the HEAL platform. This tab acts as a 'visual table of contents\u2019 of available HEAL datasets. HEAL Example Analysis \u00b6 This video introduces users to the Example Analysis page, where users can browse Jupyter notebook demos to explore previous data analyses on the HEAL platform. If your Browser does not support watching this video, here's a link to the video instead. Currently available static Jupter Notebooks: Why tutorial Notebooks? \u00b6 These notebooks will allow users to learn how to analyze and visualize data available on the HEAL platform - without having to take the additional steps of finding and exporting the data used by the tutorial first. All tutorial notebooks are static, view-only, and can be downloaded as .html files. Find the notebooks in interactive mode in the Workspace tab . Find below a description of how to work with the tutorials in the workspaces . These tutorial notebooks are meant to: Give users a sense for how the platform can be used to analyze data. Bring complementary datasets together. Be used as a launching point for the users\u2019 own custom analysis. Spark imagination about how users can incorporate the platform data access, analysis, and collaboration tools into their own research and data analysis process and pipelines. The \u201cExample Analysis\u201d tab will be regularly updated with new and exciting tutorial data analysis notebooks, as more datasets are published and brought together in novel ways on the Platform. Currently available Notebooks \u00b6 Find below a list of notebooks that are currently available and which datasets they\u2019re based on. Click here to watch demo videos about how to use the tutorial Jupyter Notebooks as a launching point for your own custom analysis. Please link your account to all FAIR repositories before working with the Notebooks in interactive mode. Notebook Name Project Title Project Number Datasets used Language BACPAC Synthetic Data Analysis Back Pain Consortium (BACPAC) Research Program Data Integration, Algorithm Development and Operations Management Center 1U24AR076730-01 1) participant_ SMART.tsv 2) substance_use_ SMART.tsv 3) physical_function_ SMART.tsv Python JCOIN Tracking Opioid Stigma Methodology and Advanced Analytics Resource Center 1U2CDA050098-01_a 1) JCOIN_NORC_ Omnibus_SURVEY1_ Feb2020.sav 2) JCOIN_NORC_ Omnibus_SURVEY2_ April2020.sav 3) JCOIN_NORC_ Omnibus_SURVEY3_ June2020.sav 4) JCOIN_NORC_ Omnibus_SURVEY4_ Oct2020.sav Python Opioid Prevalence And Overdoses 1) Drug Enforcement Administration Controlled Substances Tracking (DEA ARCOS) 2) Prescription Drug Abuse Policy System 2b) 3) CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record 1) deaarcos1 2) 57b45d83d6 c9e7e8693ccdfd 3) cdcwonder 1a) dea_arcos_drug_list.tsv 1b) dea_arcos_county_ population.tsv 1c) dea_arcos_combined_ county_annual.tsv 1d) dea_arcos_state_population.tsv 2a) 20170216-RM-Stat-Data.xlsx 2b) Naloxone_Data_09112020.xlsx 2c) 20180810_Good_Samaritan_ Law_Stat_Data.xlsx 3a) CDC_WONDER_unintentional_ overdoses.tsv 3b) CDC_WONDER_suicide_ overdoses.tsv 3c) monthly_unintentional_ overdoses.tsv Python Opioid Environment Toolkit and OEPS R (Watch tutorial) Methodology and Advanced Analytics Resource Center 1U2CDA050098-01_b 1) ZIP_COUNTY.xlsx 2) us-wide-moudsCleaned.csv 3) zctas2018.shp RStudio Opioid Overdose Trajectories (Watch tutorial) CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record cdcwonder 1) deaths_gender.xlsx 2) deaths_age_cat.xlsx 3) deaths_type_opioid.xlsx 4) cdc_wonder_year_cause_ hedegaard_et_al_2020.txt 5) cdc_wonder_year_cause_ state_hedegaard_et_al_2020.txt Python Working with the Tutorial Notebooks in interactive mode \u00b6 Notebooks require linked access to all FAIR enabled repositories, as described here . Code in the notebooks is editable, and users can import additional datasets and extend their analysis. Demo - How to find data and work on the Tutorial Notebooks \u00b6 Below we describe the steps to export data from the Discovery Page tutorial Jupyter notebooks for one example tutorial notebook BACPAC_Synthetic_Data_Analysis.ipynb (\u201cBACPAC synthetic data analysis\u201d) Users must be logged in and have their accounts linked to the FAIR repositories in order to follow the steps below. Go to the Workspace tab and click \u201cLaunch\u201d on the \u201cBACPAC Synthetic Data Analysis Notebook\u201d. This may take a few minutes to load. Note, that depending on the chosen notebook, this step varies to align with the name of the notebook/workspace. Find and open the notebook in the landing directory by clicking on \u201cBACPAC_Synthetic_Data_Analysis.ipynb\". Click the first two cells and run them by clicking into the cell and either using shift+enter on the keyboard or selecting \u201cRun\u201d. Uncomment the commands as displayed below to install necessary packages. Run the next cell to import the data files. Explore the rest of the notebook. If you want to make changes, make sure to save the notebook as a new file in the directory \"pd\". Make sure to terminate the workspace when the work is finished to reduce computational costs. Note: Work must be saved in the directory \"/pd\" in order to remain accessible after workspace termination. Note, that Workspaces automatically shut down after 90 minutes of idle time.","title":"Example Analysis Page"},{"location":"platform_example_analyses/#example-analyses","text":"The Example Analysis page contains a collection of view-only tutorial Jupyter Notebooks that provide demo analyses of datasets published on the HEAL platform. This tab acts as a 'visual table of contents\u2019 of available HEAL datasets.","title":"Example Analyses"},{"location":"platform_example_analyses/#heal-example-analysis","text":"This video introduces users to the Example Analysis page, where users can browse Jupyter notebook demos to explore previous data analyses on the HEAL platform. If your Browser does not support watching this video, here's a link to the video instead. Currently available static Jupter Notebooks:","title":"HEAL Example Analysis"},{"location":"platform_example_analyses/#why-tutorial-notebooks","text":"These notebooks will allow users to learn how to analyze and visualize data available on the HEAL platform - without having to take the additional steps of finding and exporting the data used by the tutorial first. All tutorial notebooks are static, view-only, and can be downloaded as .html files. Find the notebooks in interactive mode in the Workspace tab . Find below a description of how to work with the tutorials in the workspaces . These tutorial notebooks are meant to: Give users a sense for how the platform can be used to analyze data. Bring complementary datasets together. Be used as a launching point for the users\u2019 own custom analysis. Spark imagination about how users can incorporate the platform data access, analysis, and collaboration tools into their own research and data analysis process and pipelines. The \u201cExample Analysis\u201d tab will be regularly updated with new and exciting tutorial data analysis notebooks, as more datasets are published and brought together in novel ways on the Platform.","title":"Why tutorial Notebooks?"},{"location":"platform_example_analyses/#currently-available-notebooks","text":"Find below a list of notebooks that are currently available and which datasets they\u2019re based on. Click here to watch demo videos about how to use the tutorial Jupyter Notebooks as a launching point for your own custom analysis. Please link your account to all FAIR repositories before working with the Notebooks in interactive mode. Notebook Name Project Title Project Number Datasets used Language BACPAC Synthetic Data Analysis Back Pain Consortium (BACPAC) Research Program Data Integration, Algorithm Development and Operations Management Center 1U24AR076730-01 1) participant_ SMART.tsv 2) substance_use_ SMART.tsv 3) physical_function_ SMART.tsv Python JCOIN Tracking Opioid Stigma Methodology and Advanced Analytics Resource Center 1U2CDA050098-01_a 1) JCOIN_NORC_ Omnibus_SURVEY1_ Feb2020.sav 2) JCOIN_NORC_ Omnibus_SURVEY2_ April2020.sav 3) JCOIN_NORC_ Omnibus_SURVEY3_ June2020.sav 4) JCOIN_NORC_ Omnibus_SURVEY4_ Oct2020.sav Python Opioid Prevalence And Overdoses 1) Drug Enforcement Administration Controlled Substances Tracking (DEA ARCOS) 2) Prescription Drug Abuse Policy System 2b) 3) CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record 1) deaarcos1 2) 57b45d83d6 c9e7e8693ccdfd 3) cdcwonder 1a) dea_arcos_drug_list.tsv 1b) dea_arcos_county_ population.tsv 1c) dea_arcos_combined_ county_annual.tsv 1d) dea_arcos_state_population.tsv 2a) 20170216-RM-Stat-Data.xlsx 2b) Naloxone_Data_09112020.xlsx 2c) 20180810_Good_Samaritan_ Law_Stat_Data.xlsx 3a) CDC_WONDER_unintentional_ overdoses.tsv 3b) CDC_WONDER_suicide_ overdoses.tsv 3c) monthly_unintentional_ overdoses.tsv Python Opioid Environment Toolkit and OEPS R (Watch tutorial) Methodology and Advanced Analytics Resource Center 1U2CDA050098-01_b 1) ZIP_COUNTY.xlsx 2) us-wide-moudsCleaned.csv 3) zctas2018.shp RStudio Opioid Overdose Trajectories (Watch tutorial) CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record cdcwonder 1) deaths_gender.xlsx 2) deaths_age_cat.xlsx 3) deaths_type_opioid.xlsx 4) cdc_wonder_year_cause_ hedegaard_et_al_2020.txt 5) cdc_wonder_year_cause_ state_hedegaard_et_al_2020.txt Python","title":"Currently available Notebooks"},{"location":"platform_example_analyses/#working-with-the-tutorial-notebooks-in-interactive-mode","text":"Notebooks require linked access to all FAIR enabled repositories, as described here . Code in the notebooks is editable, and users can import additional datasets and extend their analysis.","title":"Working with the Tutorial Notebooks in interactive mode"},{"location":"platform_example_analyses/#demo-how-to-find-data-and-work-on-the-tutorial-notebooks","text":"Below we describe the steps to export data from the Discovery Page tutorial Jupyter notebooks for one example tutorial notebook BACPAC_Synthetic_Data_Analysis.ipynb (\u201cBACPAC synthetic data analysis\u201d) Users must be logged in and have their accounts linked to the FAIR repositories in order to follow the steps below. Go to the Workspace tab and click \u201cLaunch\u201d on the \u201cBACPAC Synthetic Data Analysis Notebook\u201d. This may take a few minutes to load. Note, that depending on the chosen notebook, this step varies to align with the name of the notebook/workspace. Find and open the notebook in the landing directory by clicking on \u201cBACPAC_Synthetic_Data_Analysis.ipynb\". Click the first two cells and run them by clicking into the cell and either using shift+enter on the keyboard or selecting \u201cRun\u201d. Uncomment the commands as displayed below to install necessary packages. Run the next cell to import the data files. Explore the rest of the notebook. If you want to make changes, make sure to save the notebook as a new file in the directory \"pd\". Make sure to terminate the workspace when the work is finished to reduce computational costs. Note: Work must be saved in the directory \"/pd\" in order to remain accessible after workspace termination. Note, that Workspaces automatically shut down after 90 minutes of idle time.","title":"Demo - How to find data and work on the Tutorial Notebooks"},{"location":"platform_profile_page/","text":"Profile Page \u00b6 On the profile page users will find information regarding their access to projects, access to Gen3-specific tools (e.g. access to the /workspace), and the function to create API keys for credential downloads. API keys are necessary for the downloadof files using the Gen3-client; for more information see chapter 4. Users can view their study access in the Profile Page. API keys can be viewed, created, and downloaded on the Profile Page.","title":"Profile Page"},{"location":"platform_profile_page/#profile-page","text":"On the profile page users will find information regarding their access to projects, access to Gen3-specific tools (e.g. access to the /workspace), and the function to create API keys for credential downloads. API keys are necessary for the downloadof files using the Gen3-client; for more information see chapter 4. Users can view their study access in the Profile Page. API keys can be viewed, created, and downloaded on the Profile Page.","title":"Profile Page"},{"location":"platform_request_access/","text":"Check and request access \u00b6 Users can find out to which projects they have access to by navigating to the Discovery Page and by selecting \u201cData Availability\" - \"Available\" - \u201dOK\u201d as shown below. Available data can be found when the box next to \"Available\" is selected. Access to individual Studies \u00b6 You can check access by clicking on a study in the Discovery Page, as shown below: The Study Page will display access permissions in the top right corner. Click the \u201cPermalink\u201d button in the upper right to copy the link to the clipboard. If you have access, a green box will show \u201cYou have access to this study\u201d. Access is displayed as a yellow box on top of each Study Page. Current (open-access) studies \u00b6 Current open-access studies will be shown when navigating to the Discovery Page. Users can download and/or export open-access study files after logging in. Currently, the HEAL Platform hosts the following studies. All are open-access except when noted. Note, that different studies relate to different Data Resources . Project number Study Name Data Resource 57b45d83d6c9e7e8693ccdfd Naloxone Overdose Prevention Laws PDAPS 10.3886/ICPSR34945.v3 National Mental Health Services Survey (N-MHSS) ICPSR 1U24AR076730-01 A synthetic dataset from the Back Pain Consortium (BACPAC) Research Program Data Integration, Algorithm Development and Operations Management Center HEAL 10.3886/ICPSR04256.v5 National Survey of Substance Abuse Treatment Services (N-SSATS) ICPSR cdcwonder CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record HEAL 10.3886/ICPSR30122.v5 Treatment Episode Data Set: Discharges (TEDS-D) ICPSR deaarcos1 Drug Enforcement Administration Controlled Substances Tracking (DEA ARCOS) HEAL a) 1U2CDA050098-01_a JCOIN - Methodology and Advanced Analytics Resource Center: JCOIN b) 1U2CDA050098-01_b a) JCOIN 026: Amerispeak Brief Stigma Survey JCOIN b) The Opioid Environment Policy Scan JCOIN Overview of access to Datasets and Studies \u00b6 Users can visit the \"Profile\u201d page to view a list of studies they have access to under the \u201cYou have access to the following project(s)\u201d section, as shown in the figure below. A user can view their study access in the Profile Page. From here users can also view current API keys or create and download new keys. API keys are required for downloads which require use of the Gen3-client. More information in the chapter \u201cDownloading Data Files\u201d . API keys can be viewed, created, and downloaded on the Profile Page. From here users can also view if they have access to projects or workspaces /dictionary_page: You have access to the data dictionary. /workspace: You have access to the workspace. /programs/open: You have access to open-access projects. Linking access to FAIR enabled repositories \u00b6 The HEAL Platform securely exposes data stored on multiple HEAL-approved FAIR repositories . Users need to link their account to currently all FAIR repositories in order to: run Jupyter Notebooks that utilize data stored on various FAIR repositories. export data that are stored on FAIR repositories from the Discovery Page to the Workspaces . download data that are stored on FAIR repositories from the Discovery Page . In order to link the account to the involved FAIR repositories, navigate to the Profile Page and link the account to all current login options by clicking on the \"Refresh [..] Google Login\" buttons as shown below. Linking access options on the Profile Page for data stored on FAIR enabled repositories. Access needs to be renewed after 30 days, as indicated after \"Status: expires in [..] days\". As a reminder, users will be prompted with a banner on the Workspace page and a pop-up window on the Discovery page . Users are reminded on the Workspace page to link the account to all other FAIR enabled repositories on the Profile Page. Users are reminded on the Discovery page to link the account to all other FAIR enabled repositories.","title":"Access check/request"},{"location":"platform_request_access/#check-and-request-access","text":"Users can find out to which projects they have access to by navigating to the Discovery Page and by selecting \u201cData Availability\" - \"Available\" - \u201dOK\u201d as shown below. Available data can be found when the box next to \"Available\" is selected.","title":"Check and request access"},{"location":"platform_request_access/#access-to-individual-studies","text":"You can check access by clicking on a study in the Discovery Page, as shown below: The Study Page will display access permissions in the top right corner. Click the \u201cPermalink\u201d button in the upper right to copy the link to the clipboard. If you have access, a green box will show \u201cYou have access to this study\u201d. Access is displayed as a yellow box on top of each Study Page.","title":"Access to individual Studies"},{"location":"platform_request_access/#current-open-access-studies","text":"Current open-access studies will be shown when navigating to the Discovery Page. Users can download and/or export open-access study files after logging in. Currently, the HEAL Platform hosts the following studies. All are open-access except when noted. Note, that different studies relate to different Data Resources . Project number Study Name Data Resource 57b45d83d6c9e7e8693ccdfd Naloxone Overdose Prevention Laws PDAPS 10.3886/ICPSR34945.v3 National Mental Health Services Survey (N-MHSS) ICPSR 1U24AR076730-01 A synthetic dataset from the Back Pain Consortium (BACPAC) Research Program Data Integration, Algorithm Development and Operations Management Center HEAL 10.3886/ICPSR04256.v5 National Survey of Substance Abuse Treatment Services (N-SSATS) ICPSR cdcwonder CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER) Mortality Multiple Cause-of-Death Public Use Record HEAL 10.3886/ICPSR30122.v5 Treatment Episode Data Set: Discharges (TEDS-D) ICPSR deaarcos1 Drug Enforcement Administration Controlled Substances Tracking (DEA ARCOS) HEAL a) 1U2CDA050098-01_a JCOIN - Methodology and Advanced Analytics Resource Center: JCOIN b) 1U2CDA050098-01_b a) JCOIN 026: Amerispeak Brief Stigma Survey JCOIN b) The Opioid Environment Policy Scan JCOIN","title":"Current (open-access) studies"},{"location":"platform_request_access/#overview-of-access-to-datasets-and-studies","text":"Users can visit the \"Profile\u201d page to view a list of studies they have access to under the \u201cYou have access to the following project(s)\u201d section, as shown in the figure below. A user can view their study access in the Profile Page. From here users can also view current API keys or create and download new keys. API keys are required for downloads which require use of the Gen3-client. More information in the chapter \u201cDownloading Data Files\u201d . API keys can be viewed, created, and downloaded on the Profile Page. From here users can also view if they have access to projects or workspaces /dictionary_page: You have access to the data dictionary. /workspace: You have access to the workspace. /programs/open: You have access to open-access projects.","title":"Overview of access to Datasets and Studies"},{"location":"platform_request_access/#linking-access-to-fair-enabled-repositories","text":"The HEAL Platform securely exposes data stored on multiple HEAL-approved FAIR repositories . Users need to link their account to currently all FAIR repositories in order to: run Jupyter Notebooks that utilize data stored on various FAIR repositories. export data that are stored on FAIR repositories from the Discovery Page to the Workspaces . download data that are stored on FAIR repositories from the Discovery Page . In order to link the account to the involved FAIR repositories, navigate to the Profile Page and link the account to all current login options by clicking on the \"Refresh [..] Google Login\" buttons as shown below. Linking access options on the Profile Page for data stored on FAIR enabled repositories. Access needs to be renewed after 30 days, as indicated after \"Status: expires in [..] days\". As a reminder, users will be prompted with a banner on the Workspace page and a pop-up window on the Discovery page . Users are reminded on the Workspace page to link the account to all other FAIR enabled repositories on the Profile Page. Users are reminded on the Discovery page to link the account to all other FAIR enabled repositories.","title":"Linking access to FAIR enabled repositories"},{"location":"platform_tutorial_videos/","text":"Tutorial Videos \u00b6 Watch our tutorial videos to learn how to interact with the HEAL Platform, export data files from the Discovery Page, and use the tutorial Jupyter Notebooks as a launching point for your own custom analysis. HEAL Platform Tutorial \u00b6 Watch this video to start learning about all features on the HEAL Platform. If your Browser does not support watching this video, here's a link to the video instead. The Opioid Environment Toolkit and OEPS \u00b6 This tutorial video demonstrates the use of the HEAL Platform Workspace through the analysis for the Opioid Environment Policy Scan Dataset using statistical tools written in the R programming language. If your Browser does not support watching this video, here's a link to the video instead. Opioid Overdose Trajectories \u00b6 This tutorial video demonstrates the use of the HEAL Platform to reproduce findings of a CDC study of Opioid Overdose Death rates in the United States. If your Browser does not support watching this video, here's a link to the video instead. HEAL Example Analysis \u00b6 This video introduces users to the Example Analysis page, where users can browse Jupyter notebook demos to explore previous data analyses on the HEAL platform. If your Browser does not support watching this video, here's a link to the video instead.","title":"Tutorial Videos"},{"location":"platform_tutorial_videos/#tutorial-videos","text":"Watch our tutorial videos to learn how to interact with the HEAL Platform, export data files from the Discovery Page, and use the tutorial Jupyter Notebooks as a launching point for your own custom analysis.","title":"Tutorial Videos"},{"location":"platform_tutorial_videos/#heal-platform-tutorial","text":"Watch this video to start learning about all features on the HEAL Platform. If your Browser does not support watching this video, here's a link to the video instead.","title":"HEAL Platform Tutorial"},{"location":"platform_tutorial_videos/#the-opioid-environment-toolkit-and-oeps","text":"This tutorial video demonstrates the use of the HEAL Platform Workspace through the analysis for the Opioid Environment Policy Scan Dataset using statistical tools written in the R programming language. If your Browser does not support watching this video, here's a link to the video instead.","title":"The Opioid Environment Toolkit and OEPS"},{"location":"platform_tutorial_videos/#opioid-overdose-trajectories","text":"This tutorial video demonstrates the use of the HEAL Platform to reproduce findings of a CDC study of Opioid Overdose Death rates in the United States. If your Browser does not support watching this video, here's a link to the video instead.","title":"Opioid Overdose Trajectories"},{"location":"platform_tutorial_videos/#heal-example-analysis","text":"This video introduces users to the Example Analysis page, where users can browse Jupyter notebook demos to explore previous data analyses on the HEAL platform. If your Browser does not support watching this video, here's a link to the video instead.","title":"HEAL Example Analysis"},{"location":"platform_workspaces/","text":"Workspaces \u00b6 HEAL Platform workspaces are secure data analysis environments in the cloud that can access data from one or more data resources. Workspaces include Jupyter notebooks, Python, and RStudio by default but can be configured to host virtually any application, including analysis workflows, data processing pipelines, or data visualization apps. In order to launch a workspace, users will need to request a Gen3 workspace account at \"https://healportal.org/\". There are two methods to support workspaces: grant-funded accounts paid for by your institution (STRIDES grant) or a STRIDES credit account supported by the NIH initiative. Note, it may take several days for your account to be approved . New to Jupyter? Learn more about the popular tool for data scientists on Jupyter.org (disclaimer: CTDS is not responsible for the content). Guideline to get started \u00b6 Info Workspace access requires authorization. Please contact HEAL Support for more information. After navigating to https://healdata.org/portal/workspace , users will discover a list of pre-configured virtual machine (VM) images, as shown below. Available workspaces on the HEAL Platform (top). Users may need to link their accounts from other repositories (bottom); click here to see how . (Generic) Jupyter Notebook with R kernel: Choose this VM if you are familiar with setting up Python- or R-based Notebooks, or if you just exported one or multiple studies from the Discovery Page and want to start your custom analysis. (Generic, User-licensed) Stata Notebook: Choose this VM if you are familiar with Stata-based data analysis. This notebook requires a Stata license. Tutorial Notebooks: Explore our Jupyter Notebook tutorials written in Python or RStudio, which pull data from various sources of the HEAL Data Ecosystem to leverage statistical programs and data analysis tools. All interactive tutorial notebooks can be also found as static version on the Notebook Browser tab ; read more in the section \"Example Analysis\" . Feel free to edit and experiment with this collection of notebooks. They are your personal copies! Notebooks in Python : (1) BACPAC Synthetic Data Analysis, (2) JCOIN Tracking Opioid Stigma, (3) Opioid Overdose Trajectories, (4) Opioid Prevalence And Overdoses Notebooks in RStudio : (1) Opioid Environment Toolkit and OEPS Click \u201cLaunch\u201d on any of the above workspace flavors to spin up a copy of that VM. Note: Launching the VM may take several minutes. The status of launching the workspace is displayed after clicking on \u201cLaunch\u201d. After launching, the home folders are displayed, one of which is the user's persistent drive (\"pd\"). The /pd directory is a user\u2019s persistent drive. Select the /pd folder. Only files saved in the /pd directory will remain available after termination of a workspace session. New files or licenses should be saved in the the /pd directory if users need to access them after restarting the workspaces. Attention: Any personal files in the folder \u201cdata\u201d will be lost. Personal files in the directory /pd will persist. Do not save files in the \"data\" and \u201cdata/healdata.org\u201d folders. The folder \u201chealdata.org\u201d in the \u201cdata\u201d folder will host the data files you have exported from the Discovery Page. Start a new notebook by clicking \u201cNew\u201d in the top right corner and choose between Python 3 or R Studio as the base programmatic language. Start a new notebook under \u201cNew\u201d. Experiment away! Code blocks are entered in cells, which can be executed individually or all at once. Code documentation and comments can also be entered in cells, and the cell type can be set to support Markdown. Results, including plots, tables, and graphics, can be generated in the workspace and downloaded as files. Users can import data files directly into the Notebook code after selecting files from the \"Discovery Page\" . An example is shown below. Do not forget to terminate your workspace once your work is finished to be mindful of the cost-intensive computational effort. Note, that Workspaces automatically shut down after 90 minutes of idle time. Do not forget to terminate your workspace once your work is finished. Unterminated workspaces continue to accrue computational costs. Further reading: read more about how to download data files into the Workspaces here . Upload, save, and download Files/Notebooks \u00b6 Users can upload data files or Notebooks from the local machine to the home directory by clicking on \u201cUpload\u201d and access them in the Notebook (see below). Upload data files or Notebooks to the workspace by clicking on \u201cUpload\u201d in the top right corner. On the upload screen, find your text file (in this example, it is \"this\\_is\\_a\\_demo.txt\") to upload from your local computer. Then run in the cells, for example: import os import pandas as pd os.chdir('/data') demo_df = pd.read_csv('/this_is_a_demo.txt', sep='\\t') demo_df.head() Users can save the notebook by clicking \"File\" - \"Save as\", as shown below. Save the notebook under \u201cFile\u201d - \"Save as\". Users can download notebooks by clicking \"File\" - \"Download as\", as shown below. Download the notebook as \".ipynb\". Environments, Languages, and Tools \u00b6 The following environments are available in the workspaces: Jupyter RStudio The following programmatic languages are available in Jupyter Notebooks: RStudio ( read more ) Python 3 ( read more ) Stata ( read more ) The following tools are available in Jupyter Notebooks: GitHub ( read GitHub documentation ) Python 3 and RStudio in Jupyter \u00b6 Both Python 3 and RStudio are available in Jupyter Notebooks. Users can expect to be able to use typical Python or RStudio packages, such as PyPI or CRAN. For Python and RStudio, users can start a new notebook under \"New\", as shown below. Find Python 3 or RStudio when starting a new notebook under \u201cNew\u201d. Stata in Jupyter \u00b6 Stata is available as language in Jupyter notebooks (either in Python or R kernels), but requires a license and a specific workspace. Users need to first choose the following workspace \"(Generic, User-licensed) Stata Notebook\" in order to be able to use Stata: Select this workspace to use Stata in the notebook. Users need to upload a license stata.lic to the /pd folder by selecting \"Upload\" (top right). If the upload was successful, the license appears in the directory /pd. Note , that uploading the license can also be achieved programmatically by opening a new terminal window under \"New\" - \"Terminal\", finding the directory /pd by typing: cd pd . Then, create a file using vim: vim stata.lic . This will open the file in the terminal. Users can copy the license, then hit : + wq . Then, users need to start a new notebook under \"New\" (choose either R or Python). Run the following code in the first cell: import stata_setup stata_setup.config(\"/usr/local/stata17\", \"mp\") This will return the following: Setup the license in the first cell. Users can then begin using the notebook by typing in known Stata commands, for example %% stata . describe . Troubleshooting \u00b6 If the kernel died, make sure to be logged in on 1) the Login Page 2) have enabled access to the FAIR enabled repository . Automatic Workspace Shutdown \u00b6 Workspaces automatically shut down after 90 minutes of idle time and a pop-up window will remind users before the workspace shuts down. A pop-up window will remind users to navigate back to the workspaces page in order to save the data. After the workspace has been shut down, users will be notified with the following pop-up window. Workspaces automatically shut down after 90 minutes of idle time.","title":"Workspaces"},{"location":"platform_workspaces/#workspaces","text":"HEAL Platform workspaces are secure data analysis environments in the cloud that can access data from one or more data resources. Workspaces include Jupyter notebooks, Python, and RStudio by default but can be configured to host virtually any application, including analysis workflows, data processing pipelines, or data visualization apps. In order to launch a workspace, users will need to request a Gen3 workspace account at \"https://healportal.org/\". There are two methods to support workspaces: grant-funded accounts paid for by your institution (STRIDES grant) or a STRIDES credit account supported by the NIH initiative. Note, it may take several days for your account to be approved . New to Jupyter? Learn more about the popular tool for data scientists on Jupyter.org (disclaimer: CTDS is not responsible for the content).","title":"Workspaces"},{"location":"platform_workspaces/#guideline-to-get-started","text":"Info Workspace access requires authorization. Please contact HEAL Support for more information. After navigating to https://healdata.org/portal/workspace , users will discover a list of pre-configured virtual machine (VM) images, as shown below. Available workspaces on the HEAL Platform (top). Users may need to link their accounts from other repositories (bottom); click here to see how . (Generic) Jupyter Notebook with R kernel: Choose this VM if you are familiar with setting up Python- or R-based Notebooks, or if you just exported one or multiple studies from the Discovery Page and want to start your custom analysis. (Generic, User-licensed) Stata Notebook: Choose this VM if you are familiar with Stata-based data analysis. This notebook requires a Stata license. Tutorial Notebooks: Explore our Jupyter Notebook tutorials written in Python or RStudio, which pull data from various sources of the HEAL Data Ecosystem to leverage statistical programs and data analysis tools. All interactive tutorial notebooks can be also found as static version on the Notebook Browser tab ; read more in the section \"Example Analysis\" . Feel free to edit and experiment with this collection of notebooks. They are your personal copies! Notebooks in Python : (1) BACPAC Synthetic Data Analysis, (2) JCOIN Tracking Opioid Stigma, (3) Opioid Overdose Trajectories, (4) Opioid Prevalence And Overdoses Notebooks in RStudio : (1) Opioid Environment Toolkit and OEPS Click \u201cLaunch\u201d on any of the above workspace flavors to spin up a copy of that VM. Note: Launching the VM may take several minutes. The status of launching the workspace is displayed after clicking on \u201cLaunch\u201d. After launching, the home folders are displayed, one of which is the user's persistent drive (\"pd\"). The /pd directory is a user\u2019s persistent drive. Select the /pd folder. Only files saved in the /pd directory will remain available after termination of a workspace session. New files or licenses should be saved in the the /pd directory if users need to access them after restarting the workspaces. Attention: Any personal files in the folder \u201cdata\u201d will be lost. Personal files in the directory /pd will persist. Do not save files in the \"data\" and \u201cdata/healdata.org\u201d folders. The folder \u201chealdata.org\u201d in the \u201cdata\u201d folder will host the data files you have exported from the Discovery Page. Start a new notebook by clicking \u201cNew\u201d in the top right corner and choose between Python 3 or R Studio as the base programmatic language. Start a new notebook under \u201cNew\u201d. Experiment away! Code blocks are entered in cells, which can be executed individually or all at once. Code documentation and comments can also be entered in cells, and the cell type can be set to support Markdown. Results, including plots, tables, and graphics, can be generated in the workspace and downloaded as files. Users can import data files directly into the Notebook code after selecting files from the \"Discovery Page\" . An example is shown below. Do not forget to terminate your workspace once your work is finished to be mindful of the cost-intensive computational effort. Note, that Workspaces automatically shut down after 90 minutes of idle time. Do not forget to terminate your workspace once your work is finished. Unterminated workspaces continue to accrue computational costs. Further reading: read more about how to download data files into the Workspaces here .","title":"Guideline to get started"},{"location":"platform_workspaces/#upload-save-and-download-filesnotebooks","text":"Users can upload data files or Notebooks from the local machine to the home directory by clicking on \u201cUpload\u201d and access them in the Notebook (see below). Upload data files or Notebooks to the workspace by clicking on \u201cUpload\u201d in the top right corner. On the upload screen, find your text file (in this example, it is \"this\\_is\\_a\\_demo.txt\") to upload from your local computer. Then run in the cells, for example: import os import pandas as pd os.chdir('/data') demo_df = pd.read_csv('/this_is_a_demo.txt', sep='\\t') demo_df.head() Users can save the notebook by clicking \"File\" - \"Save as\", as shown below. Save the notebook under \u201cFile\u201d - \"Save as\". Users can download notebooks by clicking \"File\" - \"Download as\", as shown below. Download the notebook as \".ipynb\".","title":"Upload, save, and download Files/Notebooks"},{"location":"platform_workspaces/#environments-languages-and-tools","text":"The following environments are available in the workspaces: Jupyter RStudio The following programmatic languages are available in Jupyter Notebooks: RStudio ( read more ) Python 3 ( read more ) Stata ( read more ) The following tools are available in Jupyter Notebooks: GitHub ( read GitHub documentation )","title":"Environments, Languages, and Tools"},{"location":"platform_workspaces/#python-3-and-rstudio-in-jupyter","text":"Both Python 3 and RStudio are available in Jupyter Notebooks. Users can expect to be able to use typical Python or RStudio packages, such as PyPI or CRAN. For Python and RStudio, users can start a new notebook under \"New\", as shown below. Find Python 3 or RStudio when starting a new notebook under \u201cNew\u201d.","title":"Python 3 and RStudio in Jupyter"},{"location":"platform_workspaces/#stata-in-jupyter","text":"Stata is available as language in Jupyter notebooks (either in Python or R kernels), but requires a license and a specific workspace. Users need to first choose the following workspace \"(Generic, User-licensed) Stata Notebook\" in order to be able to use Stata: Select this workspace to use Stata in the notebook. Users need to upload a license stata.lic to the /pd folder by selecting \"Upload\" (top right). If the upload was successful, the license appears in the directory /pd. Note , that uploading the license can also be achieved programmatically by opening a new terminal window under \"New\" - \"Terminal\", finding the directory /pd by typing: cd pd . Then, create a file using vim: vim stata.lic . This will open the file in the terminal. Users can copy the license, then hit : + wq . Then, users need to start a new notebook under \"New\" (choose either R or Python). Run the following code in the first cell: import stata_setup stata_setup.config(\"/usr/local/stata17\", \"mp\") This will return the following: Setup the license in the first cell. Users can then begin using the notebook by typing in known Stata commands, for example %% stata . describe .","title":"Stata in Jupyter"},{"location":"platform_workspaces/#troubleshooting","text":"If the kernel died, make sure to be logged in on 1) the Login Page 2) have enabled access to the FAIR enabled repository .","title":"Troubleshooting"},{"location":"platform_workspaces/#automatic-workspace-shutdown","text":"Workspaces automatically shut down after 90 minutes of idle time and a pop-up window will remind users before the workspace shuts down. A pop-up window will remind users to navigate back to the workspaces page in order to save the data. After the workspace has been shut down, users will be notified with the following pop-up window. Workspaces automatically shut down after 90 minutes of idle time.","title":"Automatic Workspace Shutdown"},{"location":"study-registration/","text":"Study Registration \u00b6 Registering Your Study Registering your study is a simple, three-step process: Request access Complete study registration Enter study-level metadata into CEDAR How to request access Overview \u00b6 The HEAL Data Platform provides a single interface where users can browse and search for all HEAL-funded studies as well as other HEAL-relevant datasets. In this way, the Platform plays a fundamental role in making HEAL data findable as part of adhering to the FAIR data principles (i.e., data should be Findable, Accessible, Interoperable and Reusable). To achieve this goal, the platform aggregates metadata about each study from multiple sources. One of these is NIH RePORTER from which basic information about all HEAL-funded studies is automatically obtained. However, there are three additional sources of metadata which the Platform can utilize: Information entered into the Center for Expanded Data Annotation and Retrieval (CEDAR) Workbench , an online platform for creating and managing metadata according to the FAIR principles Information from ClinicalTrials.gov for those clinical studies registered there Information from the data repository to which the study is submitting its data To permit the Platform to pull information from these sources, a study must be registered . Registration is the process of linking a study to one or more of the metadata/data sources listed above. This process can be performed by the Principal Investigator or another member of the research team. What if I'm not ready to submit data yet? You may register your study at any time, even if you are not yet ready to submit data to a repository. Registering your study increases its visibility on the Platform and allows the Platform and data repository to anticipate and plan for your subsequent data submission.","title":"Study Registration"},{"location":"study-registration/#study-registration","text":"Registering Your Study Registering your study is a simple, three-step process: Request access Complete study registration Enter study-level metadata into CEDAR How to request access","title":"Study Registration"},{"location":"study-registration/#overview","text":"The HEAL Data Platform provides a single interface where users can browse and search for all HEAL-funded studies as well as other HEAL-relevant datasets. In this way, the Platform plays a fundamental role in making HEAL data findable as part of adhering to the FAIR data principles (i.e., data should be Findable, Accessible, Interoperable and Reusable). To achieve this goal, the platform aggregates metadata about each study from multiple sources. One of these is NIH RePORTER from which basic information about all HEAL-funded studies is automatically obtained. However, there are three additional sources of metadata which the Platform can utilize: Information entered into the Center for Expanded Data Annotation and Retrieval (CEDAR) Workbench , an online platform for creating and managing metadata according to the FAIR principles Information from ClinicalTrials.gov for those clinical studies registered there Information from the data repository to which the study is submitting its data To permit the Platform to pull information from these sources, a study must be registered . Registration is the process of linking a study to one or more of the metadata/data sources listed above. This process can be performed by the Principal Investigator or another member of the research team. What if I'm not ready to submit data yet? You may register your study at any time, even if you are not yet ready to submit data to a repository. Registering your study increases its visibility on the Platform and allows the Platform and data repository to anticipate and plan for your subsequent data submission.","title":"Overview"},{"location":"study-registration/registering-your-study/","text":"Registering Your Study \u00b6 Upon receiving notification that you\u2019ve been granted access to register your study, please proceed with the steps outlined below. Info You must request access before you can register your study. Also, if you have not already done so, create an account with CEDAR (choose the \"Register\" option to quickly set up an account). You will need a CEDAR account to complete the registration process. Note that your CEDAR User UUID can be found at the top of your CEDAR profile page. Step 1: Login to the HEAL Data Platform \u00b6 Step 2: Find your study \u00b6 From the Discovery Page , find the study you wish to register: Click on the study to open the Study Page At the top of the Study Page, select \u2018Request Access to Register This Study\u2019 to navigate to the Study Registration form . Step 3: Complete the Study Registration form \u00b6 The Study field will already be filled in If known, a valid ClinicalTrials.gov ID (NCT #) can be entered, which will enable the platform to pull some additional metadata related to the study. If known, select the repository you have submitted data to, or intend to submit data to. This will help the Platform us and the repository to which you have submitted or will be submitting your data to anticipate and plan accordingly. If your repository is not listed, please contact us with those details. Enter the unique ID for your study within the repository. Submit your registration. Alternate steps to register a study: Login to the Study Registration form Choose the study you wish to register from the Study dropdown. Only those studies you have been approved to register will be displayed in the dropdown. Complete the form as noted above and submit. Step 4: Fill out your CEDAR form \u00b6 The act of submitting the form will result in the creation of a metadata input form within your CEDAR account: Find the form for your study under the Shared with Me folder on CEDAR (accessible in the left-hand navigation). When you enter additional data into the CEDAR form, be sure to SAVE your changes by scrolling to the bottom of the form. The HEAL Data Platform will pull entries from the CEDAR templates into the Platform to enhance search capabilities and provide increasingly robust study details.","title":"Registering Your Study"},{"location":"study-registration/registering-your-study/#registering-your-study","text":"Upon receiving notification that you\u2019ve been granted access to register your study, please proceed with the steps outlined below. Info You must request access before you can register your study. Also, if you have not already done so, create an account with CEDAR (choose the \"Register\" option to quickly set up an account). You will need a CEDAR account to complete the registration process. Note that your CEDAR User UUID can be found at the top of your CEDAR profile page.","title":"Registering Your Study"},{"location":"study-registration/registering-your-study/#step-1-login-to-the-heal-data-platform","text":"","title":"Step 1:  Login to the HEAL Data Platform"},{"location":"study-registration/registering-your-study/#step-2-find-your-study","text":"From the Discovery Page , find the study you wish to register: Click on the study to open the Study Page At the top of the Study Page, select \u2018Request Access to Register This Study\u2019 to navigate to the Study Registration form .","title":"Step 2: Find your study"},{"location":"study-registration/registering-your-study/#step-3-complete-the-study-registration-form","text":"The Study field will already be filled in If known, a valid ClinicalTrials.gov ID (NCT #) can be entered, which will enable the platform to pull some additional metadata related to the study. If known, select the repository you have submitted data to, or intend to submit data to. This will help the Platform us and the repository to which you have submitted or will be submitting your data to anticipate and plan accordingly. If your repository is not listed, please contact us with those details. Enter the unique ID for your study within the repository. Submit your registration. Alternate steps to register a study: Login to the Study Registration form Choose the study you wish to register from the Study dropdown. Only those studies you have been approved to register will be displayed in the dropdown. Complete the form as noted above and submit.","title":"Step 3:  Complete the Study Registration form"},{"location":"study-registration/registering-your-study/#step-4-fill-out-your-cedar-form","text":"The act of submitting the form will result in the creation of a metadata input form within your CEDAR account: Find the form for your study under the Shared with Me folder on CEDAR (accessible in the left-hand navigation). When you enter additional data into the CEDAR form, be sure to SAVE your changes by scrolling to the bottom of the form. The HEAL Data Platform will pull entries from the CEDAR templates into the Platform to enhance search capabilities and provide increasingly robust study details.","title":"Step 4: Fill out your CEDAR form"},{"location":"study-registration/requesting-access/","text":"Requesting Access \u00b6 Step 1: Login to the HEAL Data Platform \u00b6 Step 2: Find your study \u00b6 From the Discovery Page , find the study you wish to request access to register. Click on the study to open the Study Page At the top of the Study Page, select Request Access to Register This Study to navigate to the Study Registration Access Request form. Step 3: Complete the Study Registration Access Request Form \u00b6 The field Study Name - Grant Number will already be filled in. You will need to provide your name, your email address, institutional affiliation and role on the project/study. After submitting, you will receive an email indicating the status of your request within one business day. When approved, you will then be able to register your study .","title":"Requesting Access"},{"location":"study-registration/requesting-access/#requesting-access","text":"","title":"Requesting Access"},{"location":"study-registration/requesting-access/#step-1-login-to-the-heal-data-platform","text":"","title":"Step 1: Login to the HEAL Data Platform"},{"location":"study-registration/requesting-access/#step-2-find-your-study","text":"From the Discovery Page , find the study you wish to request access to register. Click on the study to open the Study Page At the top of the Study Page, select Request Access to Register This Study to navigate to the Study Registration Access Request form.","title":"Step 2: Find your study"},{"location":"study-registration/requesting-access/#step-3-complete-the-study-registration-access-request-form","text":"The field Study Name - Grant Number will already be filled in. You will need to provide your name, your email address, institutional affiliation and role on the project/study. After submitting, you will receive an email indicating the status of your request within one business day. When approved, you will then be able to register your study .","title":"Step 3: Complete the Study Registration Access Request Form"}]}